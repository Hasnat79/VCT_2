# Visual Counter Turing Test (VCT²)
## Overview
We introduce the Visual Counter Turing Test (VCT^2), a benchmark of approximately 130K images with prompts sourced from New York Times tweets and MS COCO captions. VCT2 highlights the limitations of current AGID techniques in detecting AI-generated images. To address the growing need for evaluation frameworks, we propose the Visual AI Index (VAI), which assesses generated images on texture complexity, color distribution, and object coherence, establishing a new standard for evaluating image-generation AI.

## Key Components:
## Dataset: ~130K images synthesized via state-of-the-art (SoTA) text-to-image generation models: <br />
Stable Diffusion 2.1 <br />
Stable Diffusion 3 <br />
Stable Diffusion XL <br />
DALL·E-3 <br />
Midjourney 6 <br />

### We make our datasets publicly available which can be accessed at:
COCO: https://huggingface.co/datasets/anonymous1233/COCO_AI
Twitter: https://huggingface.co/datasets/anonymous1233/twitter_AI

## Dual-Source Prompts:
New York Times Twitter <br />
MS COCO <br />

## Technical Features:
Evaluation Protocol: Multi-modal detection efficacy assessment <br />
Texture complexity metrics <br />
Object coherence analysis <br />
Feature representation benchmarks <br />

## Quality Assessment: 
Introduced VₐI metrics for: <br />
Perceptual authenticity <br />
Structural integrity <br />


## Resources
Standardized evaluation pipeline <br />
Reproducible benchmarking framework <br />
## Open-source datasets: <br />
COCO dataset adaptation <br />
Twitter corpus collection <br />
